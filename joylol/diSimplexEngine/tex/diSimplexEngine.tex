% LaTeX source for the diSimplexEngine document
%
\InputIfFileExists{options}{}{}
\documentclass[a4paper,openany]{amsbook}
\usepackage{disitt}
\usepackage{disitt-symbols}
\usepackage[backend=biber,style=alphabetic,citestyle=alphabetic]{biblatex}
\addbibresource{diSimplexEngine.bib}

\begin{document}
\frontmatter
\sloppy

\title[DiSimplicial Proof Theory]{Testing Mathematical Proofs: The details of
Directed Simplicial Proof Theory}
%\collectionTitle{A Mathematical Theory of Reality}
\input{frontMatter}
\subjclass[2010]{Primary unknown; Secondary unknown} %
\keywords{Keyword one, keyword two etc.}%

\begin{abstract}
This is the abstract.
\end{abstract}

%\maketitle
\tableofcontents
\mainmatter

\chapter*{Preface}

\begin{quotation}
We shall not cease from exploration \\
And the end of all our exploring \\
Will be to arrive where we started \\
And know the place for the first time.

\href{http://www.davidgorman.com/4Quartets/4-gidding.htm}{T. S. Eliot,
\textit{Little Gidding}, section `V'}
\end{quotation}

\vspace{0.5cm}

\begin{quotation}
Alice laughed. ``There's no use trying,'' she said: ``one can't believe
impossible things.'' \\ 
``I daresay you haven't had much practice,'' said the Queen. \\
``When I was your age, I always did it for half-an-hour a day. Why, sometimes
I've believed as many as six impossible things before breakfast.''

\begin{quote}
\href{http://en.wikiquote.org/wiki/Through_the_Looking-Glass#Chapter_5:_Wool_and_Water}{Lewis
Carroll (Charles Lutwidge Dodgeson), \textit{Through the Looking-Glass, and
What Alice Found There}, Chapter 5: \textit{Wool and Water}}
\end{quote}
\end{quotation}

\vspace{0.5cm}

\begin{quotation}
When you are a Bear of Very Little Brain, and you Think of Things, you find
sometimes that a Thing which seemed very Thingish inside you is quite different
when it gets out into the open and has other people looking at it.

\begin{quote}
\href{https://en.wikiquote.org/wiki/A._A._Milne#The_House_at_Pooh_Corner_.281928.29}{A. A. Milne,
\textit{House at Pooh Corner}, Chapter 6: \textit{In which Pooh invents a new
game and Eeyore joins in}}
\end{quote}
\end{quotation}

\vspace{0.5cm}

I \emph{am} a Bear of Very Little Brain, unless things are spelt out in great
detail, I am never quite sure if they are `correct'.  Being mildly dyslexic,
unless I can get a computer to keep track of these details, I am never sure if
\emph{I} might have got the details mixed-up.

This book is an attempt to spell out all of the details in sufficient detail
required to get computers to `check' \emph{informal} mathematical proofs as
typically written in standard research mathematical papers. The companion
papers, \cite{diSimplexTheory} and \cite{usingDiSimplexTheory}, provide a good
overview of the required theory and process respectively. It is highly likely
that the average reader will want to check the companion papers \emph{before}
diving into the details contained in this book\footnote{Assuming the reader even
feels compelled to read this book at all}.

Most mathematicians regard providing every last detail required for a computer
to check a proof, as possible in principle, but essentially impossible in
practice. As an avid self-publicist, in that I do not intend to `publish' any of
my papers in a `traditional' `peer-reviewed' `journal', I need to be doubly sure
that my `proofs' are correct and not simply `wishful thinking'.

This cycle of work, of which this book and its companion papers form the
foundations, is intended to provide a \emph{Mathematical} theory of
\emph{Reality}. Essentially, this mathematical theory of reality, is an
exploration of the mathematics which a finite entity can compute in a finite
amount of time. As such, it is doubly important that the correctness of this
theory should be, both, \emph{checkable} and, moreover, \emph{be checked}, by a
finite entity such as a computer.

While I have, for many years, been planning on computationally checking all of
my proofs, it wasn't until discovering the recent work on Homotopy Type Theory
\cite{HoTT}, that I realized just how possible it might be. Unfortunately, as
will become obvious from this cycle of work, neither Per Martin-L\"of's
Dependent Type Theory, nor \emph{Homotopic} Type Theory are sufficient for my
purposes. Hence the need for this book to refound mathematics on \emph{Directed
Simplicial} Type Theory.  When the `dust settles' it will be obvious that both
\emph{Dependent} Type Theory and \emph{Homotopic} Type Theory will be
sub-theories of \emph{Directed Simplicial} Type Theory.

One of the key concepts of a mathematical theory of Reality, is that it is
\emph{critically} important to keep track of the informational complexity of a
mathematical object. The realization is that finite entities, such as ourselves,
can only \TODO{find correct word} with locally finite (mathematical) objects or
proceedures. This is the essential source of non-action at a distance in
Physics.

Classical mathematics, as well as most mathematical proof tools, ignore this
informational complexity. Indeed a real number has infinite complexity. 
Classical mathematical analysis, tends to allow itself to rely on woefully
non-locally finite tools. Directed Simplicial Type Theory and its associated
Proof engine are required to keep track of this informational complexity.

\TODO{Revise this!!}
Members of the species \textit{Homeo Spaiens}, (as of this writting, ``you'' and
``me''), \emph{are} able to reason about mathematical objects of inifite
complexity.  Hence Directed Simplicial Type Theory \emph{must} be capable of
proving \emph{all} of mathematics. However, what is critical, is how the
constructive, locally-finite, mathematics is embedded in the classical,
non-locally-finite, mathematics. So we explicitly extend Per Martin-L\"of's
dependent type theory with impredicative, non-constructivist additions. As will
equally become clear in this work, Categorical thought, as opposed to classical
Zermeloâ€“Fraenkel set theory, is the most `natural' way to found
mathematics\footnote{In my days in Nortel, the groups I worked with repeatedly
asked why we did not use ``simple'' computer languages to takle our Artificial
Intelligent tasks. Our reply was always the same, while we \emph{could} program
in the language of a `raw' Turing machine, the complexity of the code base would
make our tools impossible to understand and hence maintain. The point is that
different problems have `natural' languages in which humans can more easily
understand them. My argument for using Directed Simplicial Category theory is
essentially the same. It is easier to think in a language which mimics
mathematic's focus on objects and transformations between objects than it is to
use ZFC. In fact, as we will see, Category theory is really (causal) topology
\emph{as well as} algebra, making the fundamentally topological Directed
Simplicial Category theory even more natural to an analysis of the space-time of
`Reality'.}.
\TODO{Revise this!!}

\chapter{Introduction}

\section{Mathematics from a modipotent point of view}

Modipotent is `school girl' Latin derived from \emph{modi} meaning limited, and
\emph{potent} meaning power. Finite entities such as `you' and `me', are not
`gods'. We can only interact with `Reality' in locally-finite ways. While we are
not impotent, we have no omnipotent abilities to see all of reality or to
measure or sense things to inifinite precision. Some finite beings evidently
have more power then others, however we are all limited. Ignoring the nature of
these limitations in our mathematics is the source of the continuing paradoxical
nature of Quantum Mechanics as well as our current inability to unify
Realitivity with Quantum physics in a theory of Quantum Gravity.

Classical mathematics is essentially mathematics from an omnipotent point of
view. (Real) Magnitiudes can be measured to infinite precision. (Euclidian)
Points have no extension but, again, can be located in a Cartesian space to
inifinte precision.

Directed Simplicial Theory is an attempt to found mathematics in ways which
reflect our evident lack of omnipotence. 

\section{Type Theory}

We follow HoTT, \cite{HoTT}, by considering \emph{Types} as potentially having
more `structure' than a `simple' \emph{proposition}.  Instead of assuming a
type to be an abstract homotopic space, we define a \define{Directed Simplicial
Type}{Type} to be a Directed Simplicial Complex.

\section{Mathematical objectives}

One of our primary objectives as part of the mathematical theory of Reality, is
to be able to state and prove the imprecise Bayesian Theorem for
(predicative) Topos.  To do this we need to show the existence of imprecise
measures in (predicative) Topos. Any foundation of Topos theory requires among
other things the Yoneda lemma and Sheaf theory. So we start by sketching enough
Category theory to state and prove the Yoneda lemma.

However our first attainable goal is to prove

\begin{theorem}
The following conditions are equivalent:
\begin{itemize}
  \item $f$ is an isomorphism
  \item $f$ is epic and split monic
  \item $f$ is monic and split epic
\end{itemize}
\end{theorem}

\input{diSimplexEnginePL}

\chapter{Systems Architecture}

The Directed Simplicial Type Theory (DiSiTT) engine consists of the following
interacting ``parts'':
\begin{itemize}
  \item a \LaTeX\ parser; used to allow nearly `normal' `informal' mathematics
  to be used to specify DiSiTT rules, theorems, lemmas, definitions, etc. This
  parser will parse to DiSiTT's internal data structures.
  \item a \LaTeX\ pretty printer; used to translate DiSiTT's internal data
  structures (back) into a more `informal' mathematical text based upon
  \LaTeX.
  \item a Scala based parser; used to externalize DiSiTT's internal data
  structures. This has the three fold purpose of allowing the core DiSiTT
  engine to have a simple meta-level description and provide simple methods to
  both bootstrap the engine as well as test its functionality.
  \item the DiSiTT rule processing engine. The core engine should be as simple
  possible, but at the same time to extensible by compiling acceptable DiSiTT
  rules. It is used to interpret and validate a DiSiTT proof.
  \item a DiSiTT rules compiler; used to compile a given DiSiTT rule into
  scala code suitable for use in extending the core DiSiTT rule processing
  engine.
  \item a DiSiTT rules database; used to manage mathematical theories encoded
  in DiSiTT rules.
  \item a DiSiTT rules search engine; used to search external DiSiTT rules
  archives located on the internet.
\end{itemize}
%

It is critically important that DiSiTT is a multi meta-level theory. At the
`top most' (Turing) meta-level consists of a Turing machine or theory of
recursive functions. The next `top most' (Scala) meta-level consists of the
Scala object-functional language. The next `top most' (engine) meta-level
consists of the core DiSiTT engine. The `bottom most' (rules) meta-level
consists of a given collection of accepted DiSiTT rules. The object-level
consists of the sematic category associated with a given collection of
accepted DiSiTT rules.

It is critical that the engine meta-level contains the set of ordinals less
than the first inaccessible ordinal \emph{after} the natural numbers.

The DiSiTT internal data structure will be annotated Directed Simplicial
Structures. At the meta-theory level, a Directed Simplicial Structure is
formally a pre-sheaf functor from the opposite category of Ordinals to the
category of Sets. When the `dust settles' we will see that this description
can be founded in the cannonical semantic category associated with DiSiTT
itself.

\begin{tabular}{|c|c|c|c|}
\hline  & Theory & Theory & Implementation \\ 
\hline  & Models & Logic & Scala \\ 
\hline Meta-Theory & \mTheory{\Ordinal} &  &  \\ 
\hline Theory & \Ordinal &  &  \\ 
\hline Object & \oTheory{\Ordinal} &  &  \\ 
\hline 
\end{tabular} 

\part{Inference rules}

\chapter{Introduction}

The Directed Simplicial Type Theory (DiSiTT) engine, is essentially a natural
deduction judgement programming language (JPL). In classical natural deduction
the basic \emph{judement} is a statement that a given proposition, $A$, is
\emph{true}. In DiSiTT, the basic judgements are statements that one (directed)
simplicial structure is a \emph{part} of another.

Before we proceed to looking at the rules surrounding these judgements, we need
to do some basic book-keeping. Any programming language will need to keep track
of variables in various contexts, our JPL is no different.  Natural deductions
consist of nested collections of derivations or \emph{proofs}.  Variables are
scoped to a particular nested collection of derivations.

We have a number of distinct types of derivations:
\begin{enumerate}
  \item \define{Definition}{} or \define{Subdefinition}{} used to \emph{define}
  an equivilance between two statements. Subdefinitions are numbered relative
  to their enclosing (sub)definition(s).
  \item \define{Lemma}{} or \define{Theorem}{} used to provide a number of
  \emph{hypothosized} statements followed by a number of \emph{derived}
  statements. A Lemma or Theorem is a definition of a natural deduction rule
  which can henceforth be used in any other derivation. There is an implicit
  promise that a Proof will be given either in the following text, an appendix,
  or from another work.
  \item \define{Conjectures}{} the same as a Lemma or Theorem statement but marked
  as unproven (and hence unuseable in other derivations).
  \item \define{Proofs}{} or \define{Subproofs}{} used to provide detailed natural
  deduction derivations of one or more \emph{derived} statements using the given
  \emph{hypothosized} statements. Typically a proof follows a given Lemma or
  Theorem.  However Proofs can be used as a running discusion on how to prove a
  given statement (which might only be visible by the end of the discussion).
\end{enumerate}

One of our primary aims is to produce ``journal'' ready documents, for this we
use \LaTeX\ as our primary document environment and assume that the JPL
derivations are environments inside a \LaTeX\ document. As such each of the
above derivation types are defined as \LaTeX\ environments, for example:
\begin{verbatim}
\begin{definition}
  \begin{subdefinition}
  ....
  \end{subdefinition}
\end{definition}
\end{verbatim}

Each derivation environment consists of a number of derivation statements. A
single statement consists of an optional \define{context}{} followed by a
\define{judgement}{}, where a context is a sequence of judgements:
\begin{verbatim}
\hypothesis{
  \judgement{a}{A}, 
  \judgement{b}{B},
   ...
  \judgement{x}{X}
}{
  \judgement{z}{Z}
}
\end{verbatim}
or
\begin{verbatim}
\conclusion{
  \judgement{a}{A}, 
  \judgement{b}{B},
   ...
  \judgement{x}{X}
}{
  \judgement{z}{Z}
}
\end{verbatim}

Every derivation environment must have at least one \verb|\conclusion|
statement. Multiple \verb|\conclusion| statements are considered to be mutulally
equivilant. Derivation environments need not have any \verb|\hyposthesis|
statements.  The order of statements is significant, and acts as a stack.

In a proof derivation, every \verb|\conclusion| statement must be followed by a
\verb|\followsUsing{xxx}| statement, which identifies the previously defined
derivation which justifies the previous conclusion.

\chapter{Book-keeping}

In Directed Simplicial Type Theory, there is essentially only one type of
\define{judgement}{}: the judgement that $A$ is \define{part of}{} $B$, denoted
$$\judgement{A}{B}$$ There is also the associated, derived, judgement, that an 
ordered collection of judgements (for $\alpha$ an ordinal), %
\context{ %
  \judgement{\variable{x}{1}}{\variable{A}{1}} ; %
  \judgement{\variable{x}{2}}{\variable{A}{2}} ; %
  \ldots ; %
  \judgement{\variable{x}{\alpha}}{\variable{A}{\alpha}} %
} %
is a well formed \define{context}{}, denoted %
$$\cJudgement{ %
  \judgement{\variable{x}{1}}{\variable{A}{1}} ; %
  \judgement{\variable{x}{2}}{\variable{A}{2}} ; %
  \ldots ; %
  \judgement{\variable{x}{\alpha}}{\variable{A}{\alpha}} %
}$$ %
Unlike most dependent type theories, there is no ``equality'' judgement. We are
developing a full (non-strict) category theory for which all \emph{equality}
judgements are consigned to the $\Ordinal^{th}$ ``level'', and hence do not
appear in the theory itself\footnote{For a historical precident see the pair of
papers by Michael Makkai, \cite{makkai1995FOLDS}, and
\cite{makkai1998catFound} and the references therein.}.

We define a proof relevant logic of dependent type theory based upon the
\emph{is part of} judgement. While we could follow HoTT and consider a
cumulative hierarchy of universes each contained in the previous, in fact for
the Mathematical Sciences, which is our ultimate goal, we only need the first
non-finite universe. In terms of \cite[Chapter 11]{jacobs1999catLogicTypeTh}, we
are going to construct a ``Full higher order dependent type theory''. \TODO{Or
is it Polymorphic Dependent Type theory? See section 11.5 of Jacob's book
\cite{jacobs1999catLogicTypeTh}}

To do this we need to sort out object and meta-theory levels. We do this using
Bart Jacob's excellent book, \cite{jacobs1999catLogicTypeTh}.

We are also keenly interested in (co)algebras, both algebras and co-algebras
together with their associated (co)induction. Again a good introduction to this
topic can be found in \cite{jacobs2012coalg}. Of particular importance is to
keep track of the \emph{complexity} and \emph{co-complexity} of a structure of a
given type (note that since types are themselves structures of some other type,
this means we can consider the \emph{complexity} and \emph{co-complexity} of any
type). This (co)complexity is a mapping (at the meta-theory level?) into the
ordinals assocaited with our given universe.

Since we are working in dependent type theory, any given type can depend upon
structures of a collection of other types (possibly including the given type). 
This means that we must build the language of dependent type theory
via a simultaneous multi-recursion on:
%
\begin{itemize}
  \item well-typed terms
  \item substitution
  \item contexts
  \item ``computation''
  \item type-inference
\end{itemize} 
%

\section{Variables, Terms and Contexts: The Language of DiSiTT}

We begin by specifying the \emph{language} of DiSiTT at the \emph{meta-theory}
level.

At the \emph{object} level, we are concerned with identifying, interpreting and
building \emph{spacial}, \emph{non-linear}, structures. At the meta-theory
level, we need a way to \emph{communicate} how to re-build these structures with
either ourselves, through time, or others, through space-time. The
\define{language}{} of DiSiTT provides an, essentially, linear notation with
which we can re-build any DiSiTT structure we are interested in talking about.
The critically important thing here is that there is \emph{no} canonnical
\emph{linearization} of a DiSiTT structure into a linear language term.  There
will be many language terms which represent the ``same'' spacial structure at
the object level.

We assume we have an Ordinal, \mTheory{\Ordinal}, collection of
\define{variables}{} any one of which is denoted \variable{x}{\alpha} where
$\alpha \in \mTheory{\Ordinal}$. Just to be definite, note that the collection
of ordinals in this case is in the meta-theory not in the theory or object level
of our DiSiTT system. We will often, but not always, denote that an object is in
the \emph{meta-theory} by placing a overline over the object's denotation.

For notational clarity we reserve lower case letters, \variable{x}{},
\variable{y}{} and \variable{z}{}, for variables denoting \emph{parts of} the
container. We reserve upper case letters, \variable{A}{}, \variable{B}{} and
\variable{C}{}, for the corresponding \emph{containers}. Note that a part in one
judgement might be a container in a different judgement. Finally, we reserve the
Greek letters, \variable{\alpha}{}, \variable{\beta}{} and \variable{\gamma}{},
for Ordinals.

A well formed \define{context}{} is an \emph{ordered list}, %
\[\context{ %
 \judgement{\variable{x}{1}}{\variable{A}{1}} ; %
 \judgement{\variable{x}{2}}{\variable{A}{2}} ; %
 \ldots ; %
 \judgement{\variable{x}{\alpha}}{\variable{A}{\alpha}}
},\] %
of judgements which are assumed to be valid for a given $\alpha \in \Ordinal$.

\begin{deAxiom}
\conclusion{}{\cJudgement{\cdot}}
\end{deAxiom}

\begin{deAxiom}
\hypothesis{ %
  \judgement{\variable{x}{1}}{\variable{A}{1}} ; %
  \judgement{\variable{x}{2}}{\variable{A}{2}} ; %
  \ldots ; %
  \judgement{\variable{x}{\alpha}}{\variable{A}{\alpha}} %
}{ %
  \judgement{\variable{A}{\alpha+1}}{\Universe{}{}} %
}
\conclusion{ %
}{ %
  result
}
\end{deAxiom}

\chapter{Universe}

We also postulate the existence of \emph{one} universe, \Universe{}{}. %
\begin{deAxiom} %
\conclusion{}{ %
  \Universe{}{} %
} %
\end{deAxiom} %

\chapter{Ordinals}

See the OrdinalArithmetic paper.

\chapter{Cardinals}

\chapter{Directed Simplicial Type Theory}

\chapter{Categorical Type Theory}

\chapter{Wellfounded Topos Type Theory}

\chapter{Cowellfounded Topos Type Theory}

\printbibliography
\end{document}

